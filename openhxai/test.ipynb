{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'psutil_posix' has no attribute 'getpagesize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83bebbbc30ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mredis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_output\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_SetOutputMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m from .utils._tags import (\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/_joblib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# joblib imports may raise DeprecationWarning on certain Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnumpy_pickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompressor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_compressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_format_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdisk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmemstr_to_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n\u001b[0m\u001b[1;32m     27\u001b[0m                                  \u001b[0mThreadingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialBackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                  LokyBackend)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemmappingPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_memmapping_executor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/pool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_memmapping_reducer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_memmapping_reducers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_memmapping_reducer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporaryResourcesManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_multiprocessing_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massert_spawning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_memmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdisk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelete_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_tracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Some system have a ramdisk mounted by default, we can use it instead of /tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_loky_pickler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreusable_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_reusable_executor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcloudpickle_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrap_non_picklable_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocess_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrokenProcessPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocess_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEXTRA_QUEUED_CALLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueues\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleQueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_loky_pickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loky_pickler_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkill_process_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_exitcodes_terminated_worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_prepare_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/backend/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpsutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/psutil/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mPROCFS_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/proc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pslinux\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_psplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pslinux\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOPRIO_CLASS_BE\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pslinux\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOPRIO_CLASS_IDLE\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/psutil/_pslinux.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Number of clock ticks per second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mCLOCK_TICKS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msysconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SC_CLK_TCK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mPAGESIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcext_posix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpagesize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mBOOT_TIME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# set later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mLITTLE_ENDIAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'little'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'psutil_posix' has no attribute 'getpagesize'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import redis\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to redis\n",
    "\n",
    "backend = redis.Redis(\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True,\n",
    "    password=open(\"config/secrets/db-password.txt\").read().strip(),\n",
    "    port=6666,\n",
    ")\n",
    "key_values = {key: json.loads(backend.get(key)) for key in backend.keys()}\n",
    "\n",
    "# OUTPUT_DIR = \"data/db-dump\"\n",
    "OUTPUT_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for testing purposes!\n",
    "\n",
    "# user = 'rcdv-ann-ig:user:0605_1403'\n",
    "# tmp = json.loads(backend[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 157, 150)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many links are visited\n",
    "\n",
    "file_name = \"/data/webapps/urls.csv\"\n",
    "url_df = pd.read_csv(file_name, header=None)\n",
    "print(len(url_df[url_df[1] == 1]), len(url_df), len(url_df)-len(url_df[url_df[1] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve user data from database and save as jsonl\n",
    "\n",
    "# Filter user ids during debugging\n",
    "user_ids = [k for k in key_values if \":user:\" in k and \"debug\" not in k]\n",
    "user_data = []\n",
    "\n",
    "for user in user_ids:\n",
    "    tmp = json.loads(backend[user])\n",
    "\n",
    "    experiment_id = user.split(\":\")[0]\n",
    "    user_id = user.split(\":\")[2]\n",
    "    if len(tmp['split_id']) > 1: split_id = int(tmp['split_id'][0])\n",
    "    else: split_id = int(tmp['split_id'])\n",
    "    \n",
    "    if 'consent-check' in tmp: consent_check = tmp['consent-check']\n",
    "    else: consent_check = False\n",
    "\n",
    "    if 'attention-check' in tmp: attention_check = tmp['attention-check']\n",
    "    else: attention_check = False\n",
    "    if 'attention-state' in tmp: attention_state = tmp['attention-state']\n",
    "    else: attention_state = False\n",
    "\n",
    "    if 'user-task-instances' in tmp: user_task_instances = tmp['user-task-instances']\n",
    "    else: user_task_instances = False\n",
    "\n",
    "    if 'task-state' in tmp: task_state = tmp['task-state']\n",
    "    else: task_state = False\n",
    "\n",
    "    if 'survey-check' in tmp: survey_check = tmp['survey-check']\n",
    "    else: survey_check = False\n",
    "    if 'survey-state' in tmp: survey_state = tmp['survey-state']\n",
    "    else: survey_state = False\n",
    "\n",
    "    user_data.append(\n",
    "        {\n",
    "            \"experiment_id\": experiment_id,\n",
    "            \"user_id\": user_id,\n",
    "            \"split_id\": split_id,\n",
    "            \"consent_check\": consent_check,\n",
    "            \"attention_check\": attention_check,\n",
    "            \"attention_state\": attention_state,\n",
    "            \"user_task_instances\": user_task_instances,\n",
    "            \"task_state\": task_state,\n",
    "            \"survey_check\": survey_check,\n",
    "            \"survey_state\": survey_state,\n",
    "        }\n",
    "    )\n",
    "\n",
    "user_df = pd.DataFrame(user_data)\n",
    "user_df.to_json(os.path.join(OUTPUT_DIR, \"/data/viv/user-viv.jsonl\"), lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter old data and include only experiment data\n",
    "\n",
    "user_data_path = \"/data/viv/user-viv.jsonl\"\n",
    "df = pd.read_json(user_data_path, lines=True)\n",
    "\n",
    "discarded_user_ids = [\n",
    " '62699ca4c48ff1d410fcd8f7',\n",
    " '62ba10d2cd9577af0d8744bb',\n",
    " '6282575ebe32fdc6268babc8',\n",
    " '643d681fb11898ee6b771ccf',\n",
    " '5b6515e83662a8000158b2aa',\n",
    " '63d7d95057d77b4c34b3afe8',\n",
    " '5c82c9a4d8302a00010639b8',\n",
    " '5f77c6a1a110ce346dc016ec',\n",
    " '5b5a822e1ad8270001c4f28d',\n",
    " '5e3c79de24984505f37d3903',\n",
    " '629e4d79be0e1ecd4ce30ab4',\n",
    " '5ee2e7bf21501a83d55642cd',\n",
    " '5c5a19299404f10001ff8cbf',\n",
    " '63d7e54a90879dee84dffb32', \n",
    " '6455b4121cd3166666ae1fdd',\n",
    " '61292a3404d387db5b0b2a32',\n",
    " ]\n",
    "# discarded_user_ids = []\n",
    "\n",
    "# This line excludes rows with the following criteria:\n",
    "# 1. user id that starts with 0 (we want to ignore user ids used during debugging)\n",
    "# 2. attention_state, task state, survey state are false (we only want complete data)\n",
    "# 3. remove user ids\n",
    "filtered_df = df[(~df['user_id'].str.startswith('0')) & \\\n",
    "                 ~(df['attention_state'] == False) & \\\n",
    "                 ~(df['task_state'] == False) & \\\n",
    "                 ~(df['survey_state'] == False) & \\\n",
    "                 ~(df['user_id'].isin(discarded_user_ids))]\n",
    "# filtered_df = df[(~df['user_id'].str.startswith('0'))]\n",
    "\n",
    "print(f\"len of filtered_df: {len(filtered_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>split_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>german-ann-ig</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german-ann-sg</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>german-ann-shap</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rcdv-ann-ig</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rcdv-ann-sg</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rcdv-ann-shap</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_id  split_id  count\n",
       "0     german-ann-ig         3     24\n",
       "1   german-ann-lime         1     23\n",
       "2   german-ann-lime         2     24\n",
       "3   german-ann-lime         3     22\n",
       "4     german-ann-sg         3     20\n",
       "5   german-ann-shap         3     21\n",
       "6       rcdv-ann-ig         3     16\n",
       "7     rcdv-ann-lime         1     25\n",
       "8     rcdv-ann-lime         2     26\n",
       "9     rcdv-ann-lime         3     14\n",
       "10      rcdv-ann-sg         3     26\n",
       "11    rcdv-ann-shap         3     22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line counts the number of participants each experiment_id has\n",
    "filtered_df.groupby(['experiment_id', 'split_id']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_senstitive_attribute_dict(key):\n",
    "    tmp = json.loads(backend[key])\n",
    "    assert len(tmp) == 200\n",
    "    dataset = key.split(\":\")[0].split(\"-\")[0]\n",
    "    \n",
    "    d = {}\n",
    "    for i in tmp:\n",
    "        sensitive_attribute = ''\n",
    "        # gender for German Credit and race for rcdv\n",
    "        if dataset == 'rcdv':\n",
    "            sensitive_attribute = i['features']['white']\n",
    "        if dataset == 'german':\n",
    "            if i['features']['personal-status-sex_1'] == 1 or i['features']['personal-status-sex_3'] == 1:\n",
    "                sensitive_attribute = 1 # male\n",
    "            if i['features']['personal-status-sex_2'] == 1 or i['features']['personal-status-sex_5'] == 1:\n",
    "                sensitive_attribute = 0 # female\n",
    "        instance_id = i['instance-idx']\n",
    "        d[instance_id] = sensitive_attribute\n",
    "    return d\n",
    "\n",
    "\n",
    "# Create task data senstive attributes dict\n",
    "# to retrieve sensitive attributes more easily\n",
    "\n",
    "task_data = [k for k in key_values if \"task-data\" in k and \"debug\" not in k]\n",
    "task_data_dict = {}\n",
    "for key in task_data:\n",
    "    tmp_d = create_senstitive_attribute_dict(key)\n",
    "    experiment_id = key.split(\":\")[0]\n",
    "    task_data_dict[experiment_id] = tmp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>split_id</th>\n",
       "      <th>consent_check</th>\n",
       "      <th>attention_check</th>\n",
       "      <th>attention_state</th>\n",
       "      <th>user_task_instances</th>\n",
       "      <th>task_state</th>\n",
       "      <th>survey_check</th>\n",
       "      <th>survey_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'attention-start-time': 1685998608372, 'label...</td>\n",
       "      <td>[{'instance-idx': 123, 'features': {'white': 0...</td>\n",
       "      <td>{'task-start-time': 1685998616865, 'task-progr...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'survey-start-time': 1685999119572, 'labels':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>german-ann-shap</td>\n",
       "      <td>63483c4522d65d46028da7a7</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'attention-start-time': 1685909645393, 'label...</td>\n",
       "      <td>[{'instance-idx': 177, 'features': {'duration'...</td>\n",
       "      <td>{'task-start-time': 1685909650827, 'task-progr...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'survey-start-time': 1685909863443, 'labels':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>german-ann-shap</td>\n",
       "      <td>5bebd4111296920001d55c5a</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'attention-start-time': 1685959968482, 'label...</td>\n",
       "      <td>[{'instance-idx': 78, 'features': {'duration':...</td>\n",
       "      <td>{'task-start-time': 1685959976094, 'task-progr...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'survey-start-time': 1685960588231, 'labels':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>6453a33ac9fac0b2749cb4e8</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'attention-start-time': 1685998330234, 'label...</td>\n",
       "      <td>[{'instance-idx': 190, 'features': {'duration'...</td>\n",
       "      <td>{'task-start-time': 1685998338128, 'task-progr...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'survey-start-time': 1685999095398, 'labels':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>german-ann-shap</td>\n",
       "      <td>60be1e056f39c387c4f02308</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'attention-start-time': 1685960189137, 'label...</td>\n",
       "      <td>[{'instance-idx': 9, 'features': {'duration': ...</td>\n",
       "      <td>{'task-start-time': 1685960201344, 'task-progr...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'survey-start-time': 1685960688690, 'labels':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_id                   user_id  split_id  consent_check   \n",
       "0     rcdv-ann-lime  62b0ff84054c6ca32f481c65         3           True  \\\n",
       "2   german-ann-shap  63483c4522d65d46028da7a7         3           True   \n",
       "11  german-ann-shap  5bebd4111296920001d55c5a         3           True   \n",
       "12  german-ann-lime  6453a33ac9fac0b2749cb4e8         1           True   \n",
       "13  german-ann-shap  60be1e056f39c387c4f02308         3           True   \n",
       "\n",
       "    attention_check                                    attention_state   \n",
       "0              True  {'attention-start-time': 1685998608372, 'label...  \\\n",
       "2              True  {'attention-start-time': 1685909645393, 'label...   \n",
       "11             True  {'attention-start-time': 1685959968482, 'label...   \n",
       "12             True  {'attention-start-time': 1685998330234, 'label...   \n",
       "13             True  {'attention-start-time': 1685960189137, 'label...   \n",
       "\n",
       "                                  user_task_instances   \n",
       "0   [{'instance-idx': 123, 'features': {'white': 0...  \\\n",
       "2   [{'instance-idx': 177, 'features': {'duration'...   \n",
       "11  [{'instance-idx': 78, 'features': {'duration':...   \n",
       "12  [{'instance-idx': 190, 'features': {'duration'...   \n",
       "13  [{'instance-idx': 9, 'features': {'duration': ...   \n",
       "\n",
       "                                           task_state  survey_check   \n",
       "0   {'task-start-time': 1685998616865, 'task-progr...          True  \\\n",
       "2   {'task-start-time': 1685909650827, 'task-progr...          True   \n",
       "11  {'task-start-time': 1685959976094, 'task-progr...          True   \n",
       "12  {'task-start-time': 1685998338128, 'task-progr...          True   \n",
       "13  {'task-start-time': 1685960201344, 'task-progr...          True   \n",
       "\n",
       "                                         survey_state  \n",
       "0   {'survey-start-time': 1685999119572, 'labels':...  \n",
       "2   {'survey-start-time': 1685909863443, 'labels':...  \n",
       "11  {'survey-start-time': 1685960588231, 'labels':...  \n",
       "12  {'survey-start-time': 1685999095398, 'labels':...  \n",
       "13  {'survey-start-time': 1685960688690, 'labels':...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user id: 5b4d39f2d4c93b00019c8217\n",
      "user id: 6469da01789c06be633d913f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save each user label as a row in a dataframe\n",
    "\n",
    "user_ids = set()\n",
    "\n",
    "task_data = []\n",
    "for idx, row in filtered_df.iterrows():\n",
    "    task_labels = row['task_state']['labels']\n",
    "    try:\n",
    "        assert len(task_labels) == 20\n",
    "    except:\n",
    "        print(f\"user id: {row['user_id']}\")\n",
    "\n",
    "    # Get time label on last task label\n",
    "    task_keys = list(task_labels.keys())\n",
    "    last_task_key = task_keys[len(task_keys)-1]\n",
    "    last_task_end_time = task_labels[last_task_key]['label-time']\n",
    "\n",
    "    # Get time label on last attention label\n",
    "    attention_labels = row['attention_state']['labels']\n",
    "    attention_qns_keys = list(attention_labels.keys())\n",
    "    last_attention_qn_key = attention_qns_keys[len(attention_qns_keys)-1]\n",
    "    attention_end_time = attention_labels[last_attention_qn_key]['label-time']\n",
    "\n",
    "    # Find total time taken and average time taken in seconds\n",
    "    # Divide by 100 since original timestamps are in milliseconds\n",
    "    total_time_taken_for_task = (last_task_end_time - attention_end_time) / 100 / 60\n",
    "    average_time_per_prediction = total_time_taken_for_task / len(task_labels)\n",
    "\n",
    "    count = 0\n",
    "    for index, task_label in task_labels.items():\n",
    "        # Use only the first 20 labels\n",
    "        if count > 20:\n",
    "            break\n",
    "\n",
    "        if 'instance' not in task_label:\n",
    "            break\n",
    "\n",
    "        instance_id = int(task_label['instance'])\n",
    "        experiment_id = row['experiment_id']\n",
    "\n",
    "        user_label = 0\n",
    "        try:\n",
    "            if task_label['label'] == \"will_recidivate\" or task_label['label'] == \"good\":\n",
    "                user_label = 1\n",
    "        except:\n",
    "            user_ids.add(row['user_id'])\n",
    "            break\n",
    "        actual_label = int(task_label['actual_label'])\n",
    "        prediction = int(task_label['prediction'])\n",
    "\n",
    "        task_data.append(\n",
    "            {\n",
    "                \"experiment_id\": experiment_id,\n",
    "                \"user_id\": row['user_id'],\n",
    "                \"split_id\": row['split_id'],\n",
    "                \"instance_order\": index,\n",
    "                \"instance_id\": instance_id,\n",
    "                \"user_label\": user_label,\n",
    "                \"actual_label\": actual_label,\n",
    "                \"prediction\": prediction,\n",
    "                \"sensitive_attribute\": task_data_dict[experiment_id][instance_id],\n",
    "                \"average_time\": average_time_per_prediction\n",
    "            }\n",
    "        )\n",
    "        count += 1\n",
    "\n",
    "task_df = pd.DataFrame(task_data)\n",
    "task_df.to_json(os.path.join(OUTPUT_DIR, \"/data/viv/task-viv.jsonl\"), lines=True, orient=\"records\")\n",
    "\n",
    "print(f\"user ids that need to be included in discarded: {user_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(filtered_df[filtered_df['user_id'] == '61292a3404d387db5b0b2a32']['survey_state'])\n",
    "\n",
    "# filtered_df[filtered_df['user_id'] == '61292a3404d387db5b0b2a32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>split_id</th>\n",
       "      <th>instance_order</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>user_label</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sensitive_attribute</th>\n",
       "      <th>average_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.196308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id                   user_id  split_id  instance_order   \n",
       "0  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3               0  \\\n",
       "1  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3               1   \n",
       "2  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3               2   \n",
       "3  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3               3   \n",
       "4  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3               4   \n",
       "\n",
       "   instance_id  user_label  actual_label  prediction  sensitive_attribute   \n",
       "0           90           1             0           0                    1  \\\n",
       "1           22           0             0           0                    0   \n",
       "2          154           1             0           1                    1   \n",
       "3           39           1             0           1                    1   \n",
       "4          126           1             1           1                    1   \n",
       "\n",
       "   average_time  \n",
       "0      4.196308  \n",
       "1      4.196308  \n",
       "2      4.196308  \n",
       "3      4.196308  \n",
       "4      4.196308  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_data_path = \"/data/viv/task-viv.jsonl\"\n",
    "task_df = pd.read_json(task_data_path, lines=True)\n",
    "# df.groupby(['experiment_id', 'split_id']).size().reset_index(name='count')\n",
    "task_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ids = list(task_df['user_id'].unique())\n",
    "# for user_id in user_ids:\n",
    "#     time_taken = task_df[task_df['user_id'] == user_id]['average_time'].unique()\n",
    "#     print(f\"user id {user_id} took {time_taken} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze task data with evaluation metrics\n",
    "\n",
    "def calculate_tpr_fpr(y_true, y_pred):\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape == (1, 1):\n",
    "        # Only one class present in y_true\n",
    "        tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
    "    elif cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected confusion matrix shape: {}\".format(cm.shape))\n",
    "    \n",
    "    # Avoid division by zero when calculating TPR and FPR\n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    fpr = fp / (fp + tn) if fp + tn > 0 else 0\n",
    "    return round(tpr, 3), round(fpr, 3)\n",
    "\n",
    "\n",
    "def absolute_equality_of_opportunity_difference(y_true, y_pred, sensitive_attr):\n",
    "    group_0_indices = (sensitive_attr == 0)\n",
    "    group_1_indices = (sensitive_attr == 1)\n",
    "    \n",
    "    tpr_0, _ = calculate_tpr_fpr(y_true[group_0_indices], y_pred[group_0_indices])\n",
    "    tpr_1, _ = calculate_tpr_fpr(y_true[group_1_indices], y_pred[group_1_indices])\n",
    "    \n",
    "    return np.abs(tpr_0 - tpr_1)\n",
    "\n",
    "\n",
    "def absolute_equalized_odds_difference(y_true, y_pred, sensitive_attr):\n",
    "    group_0_indices = (sensitive_attr == 0)\n",
    "    group_1_indices = (sensitive_attr == 1)\n",
    "    \n",
    "    tpr_0, fpr_0 = calculate_tpr_fpr(y_true[group_0_indices], y_pred[group_0_indices])\n",
    "    tpr_1, fpr_1 = calculate_tpr_fpr(y_true[group_1_indices], y_pred[group_1_indices])\n",
    "    \n",
    "    return (np.abs(tpr_0 - tpr_1) + np.abs(fpr_0 - fpr_1)) / 2\n",
    "\n",
    "\n",
    "conditions = task_df.apply(lambda row: f\"{row['experiment_id']}_{row['split_id']}\", axis=1).unique()\n",
    "with open(\"/data/viv/objective.txt\", \"w\") as file:\n",
    "    file.write(f\"total conditions: {len(conditions)}\\n\\n\")\n",
    "\n",
    "    for condition in conditions:\n",
    "        experiment_id = condition.split('_')[0]\n",
    "        split_id = condition.split('_')[1]\n",
    "        tmp_df = task_df[(task_df['experiment_id'] == experiment_id) & (task_df['split_id'] == int(split_id))]\n",
    "\n",
    "        time_df = tmp_df.groupby(['experiment_id', 'split_id','user_id'])['average_time'].mean().reset_index(name='average_time_per_prediction')\n",
    "        time_taken = np.mean(time_df['average_time_per_prediction'])\n",
    "\n",
    "        over_reliance = round(len(tmp_df[(tmp_df['user_label'] == tmp_df['prediction']) & (tmp_df['actual_label'] != tmp_df['prediction'])]) / len(tmp_df), 3)\n",
    "        under_reliance = round(len(tmp_df[(tmp_df['user_label'] != tmp_df['prediction']) & (tmp_df['actual_label'] == tmp_df['prediction'])]) / len(tmp_df), 3)\n",
    "\n",
    "        preds = tmp_df['prediction']\n",
    "        labels = tmp_df['actual_label']\n",
    "        user_labels = tmp_df['user_label']\n",
    "        sensitive_attr = tmp_df['sensitive_attribute']\n",
    "        assert len(preds) == len(labels) == len(user_labels) == len(tmp_df)\n",
    "        \n",
    "        accuracy = round(metrics.accuracy_score(labels, preds), 3)\n",
    "        precision = round(metrics.precision_score(labels, preds), 3)\n",
    "        recall = round(metrics.recall_score(labels, preds), 3)\n",
    "        f1 = round(metrics.f1_score(labels, preds), 3)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(labels, preds).ravel()\n",
    "\n",
    "        tpr, fpr = calculate_tpr_fpr(labels, preds)\n",
    "        aeood = round(absolute_equality_of_opportunity_difference(labels, preds, sensitive_attr), 3)\n",
    "        aeod = round(absolute_equalized_odds_difference(labels, preds, sensitive_attr), 3)\n",
    "\n",
    "        # print(f\"===== {experiment_id}:{split_id} ======\")\n",
    "        # print(f\"# of participants: {len(preds) / 20} (we want it to be around 30)\")\n",
    "        # print(f\"# of preds/labels: {len(preds)} (we want it to be around 600)\")\n",
    "        # print(f\"accuracy: {accuracy}\")\n",
    "        # print(f\"precision: {precision}\")\n",
    "        # print(f\"recall: {recall}\")\n",
    "        # print(f\"f1: {f1}\")\n",
    "        # print(f\"over reliance: {over_reliance}\")\n",
    "        # print(f\"under reliance: {under_reliance}\")\n",
    "        # print(f\"tpr: {tpr}\")\n",
    "        # print(f\"fpr: {fpr}\")\n",
    "        # print(f\"absolute equality of opportunity difference: {aeood}\")\n",
    "        # print(f\"absolute equalized odds difference: {aeod}\")\n",
    "        # print(f\"true negatives: {tn}\")\n",
    "        # print(f\"false positives: {fp}\")\n",
    "        # print(f\"false negatives: {fn}\")\n",
    "        # print(f\"true positives: {tp}\\n\")\n",
    "\n",
    "        file.write(f\"===== {experiment_id}:{split_id} ======\\n\")\n",
    "        file.write(f\"# of participants: {len(preds) / 20} (we want it to be around 30)\\n\")\n",
    "        file.write(f\"# of preds/labels: {len(preds)} (we want it to be around 600)\\n\")\n",
    "        file.write(f\"accuracy: {accuracy}\\n\")\n",
    "        file.write(f\"precision: {precision}\\n\")\n",
    "        file.write(f\"recall: {recall}\\n\")\n",
    "        file.write(f\"f1: {f1}\\n\")\n",
    "        file.write(f\"over reliance: {over_reliance}\\n\")\n",
    "        file.write(f\"under reliance: {under_reliance}\\n\")\n",
    "        file.write(f\"tpr: {tpr}\\n\")\n",
    "        file.write(f\"fpr: {fpr}\\n\")\n",
    "        file.write(f\"absolute equality of opportunity difference: {aeood}\\n\")\n",
    "        file.write(f\"absolute equalized odds difference: {aeod}\\n\")\n",
    "        file.write(f\"true negatives: {tn}\\n\")\n",
    "        file.write(f\"false positives: {fp}\\n\")\n",
    "        file.write(f\"false negatives: {fn}\\n\")\n",
    "        file.write(f\"true positives: {tp}\\n\")\n",
    "        file.write(f\"time taken per prediction in minutes: {time_taken}\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each survey label as a row in a dataframe\n",
    "\n",
    "likert_score_conversion = {\n",
    "    \"Strongly Disagree\": 1,\n",
    "    \"Disagree\": 2,\n",
    "    \"Neutral\": 3,\n",
    "    \"Agree\": 4,\n",
    "    \"Strongly Agree\" : 5,\n",
    "}\n",
    "\n",
    "survey_data = []\n",
    "for idx, row in filtered_df.iterrows():\n",
    "    survey_labels = row['survey_state']['labels']\n",
    "\n",
    "    for index, survey_label in survey_labels.items():\n",
    "        instance_id = int(task_label['instance'])\n",
    "        experiment_id = row['experiment_id']\n",
    "        survey_label = survey_label['label']\n",
    "\n",
    "        survey_data.append(\n",
    "            {\n",
    "                \"experiment_id\": experiment_id,\n",
    "                \"user_id\": row['user_id'],\n",
    "                \"split_id\": row['split_id'],\n",
    "                \"question_number\": index,\n",
    "                \"survey_label\": survey_label,\n",
    "                \"survey_label_score\": likert_score_conversion.get(survey_label, False),\n",
    "            }\n",
    "        )\n",
    "\n",
    "survey_df = pd.DataFrame(survey_data)\n",
    "survey_df.to_json(os.path.join(OUTPUT_DIR, \"/data/viv/survey-viv.jsonl\"), lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>split_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>survey_label</th>\n",
       "      <th>survey_label_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>That was very well put together. Very interest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Agree</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Agree</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>62b0ff84054c6ca32f481c65</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Agree</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id                   user_id  split_id  question_number   \n",
       "0  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3                0  \\\n",
       "1  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3                1   \n",
       "2  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3                2   \n",
       "3  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3                3   \n",
       "4  rcdv-ann-lime  62b0ff84054c6ca32f481c65         3                4   \n",
       "\n",
       "                                        survey_label  survey_label_score  \n",
       "0  That was very well put together. Very interest...                   0  \n",
       "1                                              Agree                   4  \n",
       "2                                            Neutral                   3  \n",
       "3                                              Agree                   4  \n",
       "4                                              Agree                   4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data_path = \"/data/viv/survey-viv.jsonl\"\n",
    "survey_df = pd.read_json(survey_data_path, lines=True)\n",
    "# df.groupby(['experiment_id', 'split_id', 'user_id']).size().reset_index(name='count')\n",
    "survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survey data\n",
    "\n",
    "conditions = survey_df.apply(lambda row: f\"{row['experiment_id']}_{row['split_id']}\", axis=1).unique()\n",
    "with open(\"/data/viv/subjective.txt\", \"w\") as file:\n",
    "    file.write(f\"total conditions: {len(conditions)}\\n\\n\")\n",
    "\n",
    "    for condition in conditions:\n",
    "        experiment_id = condition.split('_')[0]\n",
    "        split_id = condition.split('_')[1]\n",
    "        condition_df = survey_df[(survey_df['experiment_id'] == experiment_id) & (survey_df['split_id'] == int(split_id))]\n",
    "        file.write(f\"===== {experiment_id}:{split_id} ======\\n\")\n",
    "\n",
    "        survey_qns = [i for i in range(1, 17)]\n",
    "        if split_id == '1': \n",
    "            survey_qns = [i for i in range(1, 17) if i not in range(2, 17)]\n",
    "        if split_id == '2': \n",
    "            survey_qns = [i for i in range(1, 17) if i not in [4, 10, 11, 12, 13, 14]]\n",
    "\n",
    "        for qn in survey_qns:\n",
    "            tmp_df = condition_df[(condition_df['question_number'] == qn)]\n",
    "            mean = np.mean(tmp_df['survey_label_score'])\n",
    "            std = np.std(tmp_df['survey_label_score'])\n",
    "            # print(f\"survey question {qn}\")\n",
    "            # print(f\"mean: {round(mean, 3)}, std: {round(std, 3)}\\n\")\n",
    "\n",
    "            file.write(f\"{qn}. mean: {round(mean, 3)}, std: {round(std, 3)}\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/home/vivlai/openhxai/config/rcdv/codebook.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     note = str(row['note'])\n",
    "#     if note.strip() != '' and note.strip() != 'nan':\n",
    "#         tmp = row['variable full name']\n",
    "#         variable = re.sub(r'\\(.*\\)', '', tmp).strip()\n",
    "\n",
    "#         print(f\"<p>{variable} - {note}</p>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/home/vivlai/openhxai/config/german/codebook.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     note = str(row['note'])\n",
    "#     if note.strip() != '' and note.strip() != 'nan':\n",
    "#         tmp = row['variable full name']\n",
    "#         variable = re.sub(r'\\(.*\\)', '', tmp).strip()\n",
    "\n",
    "#         print(f\"<p>{variable} - {note}</p>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>split_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>german-ann-ig</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german-ann-lime</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german-ann-sg</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>german-ann-shap</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rcdv-ann-ig</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rcdv-ann-lime</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rcdv-ann-sg</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rcdv-ann-shap</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_id  split_id  count\n",
       "0     german-ann-ig         3     24\n",
       "1   german-ann-lime         1     23\n",
       "2   german-ann-lime         2     24\n",
       "3   german-ann-lime         3     22\n",
       "4     german-ann-sg         3     20\n",
       "5   german-ann-shap         3     21\n",
       "6       rcdv-ann-ig         3     16\n",
       "7     rcdv-ann-lime         1     25\n",
       "8     rcdv-ann-lime         2     26\n",
       "9     rcdv-ann-lime         3     14\n",
       "10      rcdv-ann-sg         3     26\n",
       "11    rcdv-ann-shap         3     22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line counts the number of participants each experiment_id has\n",
    "count_df = filtered_df.groupby(['experiment_id', 'split_id']).size().reset_index(name='count')\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining HITs to run: 97\n"
     ]
    }
   ],
   "source": [
    "# Find out how many more splits are needed to generate in urls.csv\n",
    "\n",
    "ideal_count_of_participants = 30\n",
    "leeway = 5\n",
    "total_remaining = 0\n",
    "\n",
    "count_dict = {}\n",
    "for idx, row in count_df.iterrows():\n",
    "    condition = f\"{row['experiment_id']}_{row['split_id']}\"\n",
    "    count = row['count']\n",
    "    remaining = ideal_count_of_participants - count\n",
    "    total_remaining += remaining\n",
    "    count_dict[condition] = remaining + leeway\n",
    "\n",
    "# print(count_dict)\n",
    "print(f\"remaining HITs to run: {total_remaining}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_url_dict = {\n",
    " 'rcdv-ann-lime_1': \"https://openhexai1.machineintheloop.com/?userId=_&splitId=1\",\n",
    " 'rcdv-ann-lime_2': \"https://openhexai1.machineintheloop.com/?userId=_&splitId=2\",\n",
    " 'rcdv-ann-lime_3': \"https://openhexai1.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'rcdv-ann-shap_3': \"https://openhexai1b.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'rcdv-ann-ig_3': \"https://openhexai1c.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'rcdv-ann-sg_3': \"https://openhexai1d.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'german-ann-lime_1': \"https://openhexai2.machineintheloop.com/?userId=_&splitId=1\",\n",
    " 'german-ann-lime_2': \"https://openhexai2.machineintheloop.com/?userId=_&splitId=2\",\n",
    " 'german-ann-lime_3': \"https://openhexai2.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'german-ann-shap_3': \"https://openhexai2b.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'german-ann-ig_3': \"https://openhexai2c.machineintheloop.com/?userId=_&splitId=3\",\n",
    " 'german-ann-sg_3': \"https://openhexai2d.machineintheloop.com/?userId=_&splitId=3\",\n",
    "}\n",
    "\n",
    "all_urls = []\n",
    "for condition, count in count_dict.items():\n",
    "    url = condition_url_dict[condition]\n",
    "    for i in range(count):\n",
    "        all_urls.append(f\"{url},0\")\n",
    "\n",
    "assert len(all_urls) == sum(list(count_dict.values()))\n",
    "\n",
    "random.shuffle(all_urls)\n",
    "\n",
    "file_name = \"/data/webapps/urls.csv\"\n",
    "with open(file_name, 'w') as file:\n",
    "    for url in all_urls:\n",
    "        file.write(url + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 157, 157)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"/data/webapps/urls.csv\"\n",
    "url_df = pd.read_csv(file_name, header=None)\n",
    "print(len(url_df[url_df[1] == 1]), len(url_df), len(url_df)-len(url_df[url_df[1] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
